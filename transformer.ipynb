{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python提供了`__future__`模块，把下一个新版本的特性导入到当前版本，于是我们就可以在当前版本中测试一些新版本的特性。  \n",
    "`re`是正则表达式模块  \n",
    "`torch.optim`是为了更方便的更新  \n",
    "这个网址 https://blog.csdn.net/stupid_3/article/details/83184691 和B站李宏毅的课程讲的比较清楚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device=\"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "NNNN_token = 2#这个是用于补足句子的\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"SOS\": 0, \"EOS\": 1, \"NNNN\": 2}\n",
    "        self.word2count = {\"SOS\": 0, \"EOS\": 0, \"NNNN\": 0}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"NNNN\"}\n",
    "        self.n_words = 3  # Count SOS and EOS and NNNN\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "MAX_LEN = 12\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "def standardizeSeq(s):\n",
    "    return \"SOS \" + s + \" EOS\" + \" NNNN\" * (MAX_LEN - len(s.split(' ')) - 2)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    #这个是前面不补SOS，后面不补EOS，也不补助的情况。\n",
    "    #return [pair for pair in pairs if filterPair(pair)]\n",
    "    #这个是补了SOS，EOS，且长度补齐的情况\n",
    "    return [(standardizeSeq(pair[0]), standardizeSeq(pair[1])) for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4346\n",
      "eng 2804\n",
      "('SOS je suis sur de son nom . EOS NNNN NNNN NNNN', 'SOS i m sure about his name . EOS NNNN NNNN NNNN')\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各个变量的维度：以下为singal head,现在代码实现了multihead,代码中不一样的已标出（这个和下面的矩阵横竖是一样的，第一维是横，一般输入也是第一维是长度嘛，然后竖着表示特征数）  \n",
    "input: len \\* input_size(特征数）  \n",
    "output: len \\* input_size(特征数)  \n",
    "matq: len \\* hidden_size  \n",
    "matv: 同上  \n",
    "matk: 同上  \n",
    "scale:  那个就是指 $\\sqrt{output\\_size}$ ，除以就是减小结果  \n",
    "然后是我的代码中的:  \n",
    "attention: 与论文中的不一样，就是q,v产生的，len \\* len  \n",
    "mattv: 这个是论文中的attention, len \\* hidden_size  \n",
    "y: len \\* input_size\n",
    "首先我们要明白self-attention是什么，其实它输入输出和RNN是一样的，就是用于替换RNN层  \n",
    "各个变量的现实意义：  \n",
    "个人理解：q表示询问，可以理解当前这个元素的信息，而k则是key，可以理解为询问对这个问题产生的关注是多少，将这个元素和某个元素组合，得到attention，v则是值，表示当前元素的值，用于经过这样的attention,最后产生的影响\n",
    "![avatar](self-attention1.jpg)\n",
    "然后我们可以把向量叠成matrix来简化运算,其中q,k,v都是input通过矩阵乘法产生的\n",
    "![avatar](matrix1.jpg) ![avatar](matrix2.jpg)\n",
    "首先理解scaledDotProductAttention是在干什么：  \n",
    "![avatar](scaled_dot-product_attention.jpg)  \n",
    "scaledDotAttention就是在干这个，之所以可以写成矩阵乘法就是如同上面的那个图，下面贴一个完整的图：\n",
    "![avatar](sdpa.jpg)\n",
    "其中的那个scale就是前面说的除以减小结果的意思  \n",
    "而mask就是为了不再不必要的地方产生attention，比如为了使句子长度相同而后补的0，比如在decoder时输出时不应看到未来的，例如现在在句中的位置t，\n",
    "就应仅与句子中的t-1前的内容产生attention。而mask的方法就是在那些位置填-inf,这样softmax后就变成0了。下面的`tensor.mask_fill_(bool_matrix,value)`  \n",
    "下面是multiheadAttention  \n",
    "![avatar](mha.jpg)\n",
    "concat就是把几个head拼接起来，h是head的数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意linear是这样瞎搞的，它的输入也是第一维是长度，和前面是对应的，中间随你放多少维，反正最后一维是特征数\n",
    "![avatar](linear.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, head = 2):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hidden_dim = hidden_size // head\n",
    "        self.input_size = input_size\n",
    "        self.head = head\n",
    "        \n",
    "        self.qlinear = nn.Linear(input_size,hidden_size)\n",
    "        self.vlinear = nn.Linear(input_size,hidden_size)\n",
    "        self.klinear = nn.Linear(input_size,hidden_size)\n",
    "        self.ylinear = nn.Linear(hidden_size,input_size)\n",
    "        \n",
    "    def scaledDotProductAttention(self, matq, matk, matv, mask):\n",
    "        scale = matk.size(-1)**0.5\n",
    "        matt = matq.matmul(matk.transpose(1,2))/scale  #(head, N, hidden_dim) * (head, hidden_dim, N) -> (head, N, N)\n",
    "        if not mask is None:\n",
    "            matt.masked_fill_(mask, -np.inf)\n",
    "        matt = F.softmax(matt, dim=-1)  #(head, N, N) * (head, N, hidde_dim)\n",
    "        mattv = matt.matmul(matv)\n",
    "        return torch.cat(torch.chunk(mattv.view(-1,self.hidden_dim), self.head,0), dim = 1) #(head, N, hidden_dim) ->(N, hidden_size)\n",
    "    \n",
    "    def toMulti(self, matx):#这里是把特征等分\n",
    "        return torch.cat(torch.chunk(matx, self.head, -1),dim=0).view(self.head, -1, self.hidden_dim)\n",
    "    \n",
    "    def forward(self, inputq, inputk, inputv, mask = None):\n",
    "        matq = self.toMulti(self.qlinear(inputq))\n",
    "        matv = self.toMulti(self.vlinear(inputv))\n",
    "        matk = self.toMulti(self.klinear(inputk))\n",
    "        mattv = self.scaledDotProductAttention(matq, matk, matv, mask)\n",
    "        y = self.ylinear(mattv)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequece_mask(input):\n",
    "    len = input.size(-2)\n",
    "    return torch.triu(torch.ones((len,len), dtype = torch.bool), diagonal = 1).to(device)\n",
    "    #里面ones和zeros差不多，就是产生1； dtype之所以用这个是因为mask需要为bool\n",
    "    #而triu函数则是将参数一的上三角部分返回回去，剩下的补0，而diagonal决定了是否多返回或少返回，看下面这张图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](triu.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3875, -0.2006,  0.3170, -0.2971,  0.1688],\n",
      "        [ 0.2606, -0.0670,  0.4240, -0.3522,  0.1500],\n",
      "        [ 0.3206, -0.1465,  0.3349, -0.4020,  0.1780],\n",
      "        [ 0.2632, -0.0559,  0.4544, -0.2865,  0.1342],\n",
      "        [ 0.3246, -0.1183,  0.4079, -0.2498,  0.1408],\n",
      "        [ 0.3193, -0.1351,  0.3595, -0.3562,  0.1661]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "#开始检查没有mask的对不对\n",
    "model1 = MultiHeadAttention(5, 2).to(device)\n",
    "input1 = torch.randn(6,5).to(device)\n",
    "y1 = model1(input1,input1,input1)\n",
    "print(y1)\n",
    "torch.sum(y1).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2618,  0.5105, -0.5245, -0.1616, -0.6298],\n",
      "        [-0.2770,  0.5536, -0.5358, -0.2473, -0.6445],\n",
      "        [-0.2678,  0.5127, -0.5555, -0.1879, -0.6279],\n",
      "        [-0.2697,  0.5786, -0.4471, -0.2286, -0.6614],\n",
      "        [-0.2618,  0.5474, -0.4578, -0.1801, -0.6491],\n",
      "        [-0.2392,  0.5413, -0.3367, -0.0820, -0.6574]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "#开始检查有mask的对不对\n",
    "model1 = MultiHeadAttention(5, 2).to(device)\n",
    "input1 = torch.randn(6,5).to(device)\n",
    "y1 = model1(input1,input1,input1,torch.tensor([[False,False,False,False,False,True]]*6).to(device))\n",
    "print(y1)\n",
    "torch.sum(y1).backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "位置编码，讲解见后，这里仅给出公式以及这个公式为什么可行：\n",
    "$$PE_{(pos,2*i)} = sin(pos/{10000^{2i/d_{model}}})$$\n",
    "$$PE_{(pos,2*i+1)} = cos(pos/{10000^{2i/d_{model}}})$$\n",
    "这所以可行，是因为这不仅可以表示绝对位置，也可以表示相对位置，$sin(x+y)=sin(x)cos(y)+cos(x)sin(y)$，这意味着$PE(pos+k)$可以用$PE(pos)$和$PE(k)$来表示，故可以表示相对位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEncoding(nn.Module):\n",
    "    def __init__(self, max_len, word_size):\n",
    "        super(PositionEncoding, self).__init__()\n",
    "        self.position_mat = torch.tensor([[pos/np.power(10000,i//2*2/word_size) for i in range(word_size)] for pos in range(max_len)], \\\n",
    "                                        dtype = torch.float32).to(device)\n",
    "        self.position_mat[:,0::2] = torch.sin(self.position_mat[:,0::2])\n",
    "        self.position_mat[:,1::2] = torch.cos(self.position_mat[:,1::2])\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return input + self.position_mat[0:input.size(-2),0:input.size(-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](transformer.jpg)\n",
    "embedded: len \\* word_size 这里面需要考虑位置的影响，不然之前那样不考虑位置是不科学的，这个就是有一种奇特的方法加上一个向量。为什么是加呢？\n",
    "可以这样理解：把原来的input延长，补一个位置one-hot变量，那么乘一个矩阵压到这么多维，可以相等于加一个矩阵。embedding的格式\n",
    "就是把input的每个元素都扩展成word_size维的向量，它的两个重要参数第一个是字典大小，第二个是word_size。后面那个参数padding_idx=0表示遇到这个数时生成全为0的向量，比如你输入为了补齐，补了一些0(这份代码补的是2)，这些啥用都没有，就直接生成全0就好了\n",
    "output: len \\* word_size  \n",
    "output2: len \\* word_size  \n",
    "图中每一个的意义： \n",
    "n:首先这个是进行了多次，原论文是6次，本次本着性能不足的原因，就进行一次，若要多次，可把这个封装成一个类，在encodertran调多次即可。  \n",
    "add:就是input+output，加的目的是使梯度>1，防止梯度消失   \n",
    "norm:就是layernormalization  \n",
    "feed forward:就是一个最普通前馈式神经网络，为什么要接这个我也不明白。网上有大佬说接这个是为了使更有效（expressiveness，不知道咋翻译），理由是\n",
    "前面的都是线性的，而这个可以带来了一些非线性的混合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalization归一化：使数据的均值和方差变成指定的数，方便学习。\n",
    "![avatar](layernorm.jpg)\n",
    "那个E是均值的意思，Var是方差的意思，$\\gamma$是新的方差，$\\beta$是新的均值  \n",
    "layerNormalization就是把一个数据自身的所有特征进行normalization，而batchNormalization就是把一个batch的所有数据的同一个特征拿来normalization  \n",
    "至于为什么要有$\\gamma$$\\beta$，网上大佬的解释是使他具有capacity，比如如果你后接了一个ReLU,没这个的话一半的输入都输出0，就太不合理了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderTran(nn.Module):\n",
    "    #word_number是指字典大小，word_size是embedding的产生出来的size,hidden_size就是multiheadAttention中的hidden_size\n",
    "    #ff_size就是那个前馈式神经网络的隐藏层，max_len就是句子的最长长度，是用来处理位置向量的\n",
    "    def __init__(self, word_number, word_size = 256, hidden_size = 380, ff_size = 400, max_len = MAX_LEN):\n",
    "        super(EncoderTran, self).__init__()\n",
    "        self.word_size = word_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.ff_size = ff_size\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.embedding = nn.Embedding(word_number, word_size, padding_idx = 2)\n",
    "        self.position_mat = PositionEncoding(max_len, word_size)\n",
    "        self.multi_head_attention = MultiHeadAttention(word_size,hidden_size)\n",
    "        self.layernorm1 = nn.LayerNorm(word_size)#里面直接填特征数就可以了，输入len * 特征数就可以了\n",
    "        self.ffn_linear1 = nn.Linear(word_size, ff_size)\n",
    "        self.ffn_linear2 = nn.Linear(ff_size,word_size)\n",
    "        self.layernorm2 = nn.LayerNorm(word_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        embedded =  self.position_mat(self.embedding(input))\n",
    "        #这个mask会自动广播，可以结合图看，只需要使得attention矩阵涉及0的竖行为0就可以了，\n",
    "        #因为横行一是不影响，aij才表示j位置对i位置的attention,只要使添0的地方对有内容的不影响就行了\n",
    "        #二是反正softmax前都全为0，即使写出了-inf一是一样的\n",
    "        output = self.multi_head_attention(embedded, embedded, embedded, input.eq(2))\n",
    "        output = self.layernorm1(output + embedded)\n",
    "        output2 = self.ffn_linear2(F.relu(self.ffn_linear1(output)))\n",
    "        output2 = self.layernorm2(output2+output)\n",
    "        return output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#开始检查对不对\n",
    "model1 = EncoderTran(10, 5, 4, 3, 9).to(device)#小细节，测试的时候不要让维度有相同的数，这样可以检查维度正不正确\n",
    "input1 = torch.tensor([1,2,7,8,0,9,7,2]).to(device)\n",
    "y1 = model1(input1)\n",
    "print(y1)\n",
    "torch.sum(y1).backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：此处，我们让输出和输入长度在训练时都是相同的，方便以后改成可以不一个一个输入，一个batch一个batch输入的情况，在第二个attention(即encoder-decoder attention）那里，注意维度，下面用1指代input，2用来output指代翻译出来的句子。  \n",
    "matq: len2 \\* word_size  \n",
    "matk: len1 \\* word_size  \n",
    "matv: len1 \\* word_size  \n",
    "attention: len2 \\* len1  \n",
    "output2: len2 \\* word_size  \n",
    "此处已经不需要mask了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderTran(nn.Module):\n",
    "    def __init__(self,  word_number, word_size = 256, hidden_size = 380, ff_size = 400, max_len = MAX_LEN):\n",
    "        super(DecoderTran, self).__init__()\n",
    "        self.word_size = word_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.ff_size = ff_size\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.embedding = nn.Embedding(word_number, word_size, padding_idx = 2)\n",
    "        self.position_mat = PositionEncoding(max_len, word_size)\n",
    "        \n",
    "        self.multi_head_attention1 = MultiHeadAttention(word_size,hidden_size)\n",
    "        self.layernorm1 = nn.LayerNorm(word_size)\n",
    "        \n",
    "        self.multi_head_attention2 = MultiHeadAttention(word_size,hidden_size)#调用这个的时候确实padding_mask想不清楚，不管了\n",
    "        self.layernorm2 = nn.LayerNorm(word_size)\n",
    "        \n",
    "        self.ffn_linear1 = nn.Linear(word_size, ff_size)\n",
    "        self.ffn_linear2 = nn.Linear(ff_size,word_size)\n",
    "        self.layernorm2 = nn.LayerNorm(word_size)\n",
    "        \n",
    "        self.ans_linear = nn.Linear(word_size,word_number)\n",
    "    \n",
    "    def forward(self, input, enc_output):\n",
    "        embedded =  self.position_mat(self.embedding(input))\n",
    "        output = self.multi_head_attention1(embedded, embedded, embedded, sequece_mask(embedded))\n",
    "        output = self.layernorm1(output + embedded)\n",
    "        \n",
    "        output2 = self.multi_head_attention2(output, enc_output, enc_output)#注意顺序\n",
    "        output2 = self.layernorm2(output2 + output)\n",
    "        \n",
    "        output3 = self.ffn_linear2(F.relu(self.ffn_linear1(output2)))\n",
    "        output3 = self.layernorm2(output3+output2)\n",
    "        \n",
    "        output4 = F.log_softmax(self.ans_linear(output3),dim=1)\n",
    "        return output4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.9119, -2.8814, -3.4928, -1.8626, -2.3670, -2.1591, -2.3321, -1.3360,\n",
      "         -2.2288, -3.6094],\n",
      "        [-3.2929, -3.6101, -3.3831, -1.6523, -1.9148, -2.6003, -1.9952, -2.3864,\n",
      "         -1.3948, -4.3591],\n",
      "        [-2.7500, -3.2198, -2.9127, -1.8429, -1.7206, -3.0195, -2.1177, -2.9308,\n",
      "         -1.3646, -3.6314],\n",
      "        [-3.0787, -3.5555, -3.1884, -1.8419, -1.7493, -2.6862, -1.9707, -2.9525,\n",
      "         -1.2892, -4.1007],\n",
      "        [-2.9769, -3.1763, -4.1061, -1.3027, -2.4569, -2.2237, -2.3894, -1.7355,\n",
      "         -1.9452, -4.2553]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "#开始检查对不对\n",
    "model1 = EncoderTran(10, 5, 4, 3, 9).to(device)#小细节，测试的时候不要让维度有相同的数，这样可以检查维度正不正确\n",
    "input1 = torch.tensor([1,2,7,8,3,9,7,2,0]).to(device)\n",
    "y1 = model1(input1)\n",
    "\n",
    "model2 = DecoderTran(10, 5, 4, 3, 9).to(device)\n",
    "input2 = torch.tensor([3,5,7,8,3]).to(device)\n",
    "y2 = model2(input2, y1)\n",
    "print(y2)\n",
    "torch.sum(y1).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    #indexes.append(EOS_token),前面添加了\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1)#这里把它变成了一个向量\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "('SOS je ne suis pas comme toi . EOS NNNN NNNN NNNN', 'SOS i am not like you . EOS NNNN NNNN NNNN NNNN')\n",
      "(tensor([   0,    7,  298,   12,  247, 1287,  118,    6,    1,    2,    2,    2],\n",
      "       device='cuda:0'), tensor([  0,   3,  17, 148, 744, 130,   5,   1,   2,   2,   2,   2],\n",
      "       device='cuda:0'))\n",
      "('SOS nous sommes juste la . EOS NNNN NNNN NNNN NNNN NNNN', 'SOS we re right here . EOS NNNN NNNN NNNN NNNN NNNN')\n",
      "(tensor([  0, 124, 127, 382, 203,   6,   1,   2,   2,   2,   2,   2],\n",
      "       device='cuda:0'), tensor([ 0, 78, 79, 68, 47,  5,  1,  2,  2,  2,  2,  2], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "#测试：\n",
    "print(input_lang.word2index[\"NNNN\"])\n",
    "pair=random.choice(pairs)\n",
    "print(pair)\n",
    "print(tensorsFromPair(pair))\n",
    "pair=random.choice(pairs)\n",
    "print(pair)\n",
    "print(tensorsFromPair(pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个函数每次是在拿一个句子进行训练，句子在之前已经补足\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "\n",
    "    #清空梯度\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    encoder_outputs = encoder(input_tensor)\n",
    "    \n",
    "    decoder_outputs = decoder(target_tensor, encoder_outputs)\n",
    "    loss = criterion(decoder_outputs[0:-1], target_tensor[1:])\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m,s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里才是总的训练\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.005):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0].to(device)\n",
    "        target_tensor = training_pair[1].to(device)\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters), iter, iter / n_iters * 100, print_loss_avg))\n",
    "        \n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0m 26s (- 8m 16s) (1000 5%) 0.2264\n",
      "0m 52s (- 7m 54s) (2000 10%) 0.1849\n",
      "1m 19s (- 7m 30s) (3000 15%) 0.1703\n",
      "1m 46s (- 7m 4s) (4000 20%) 0.1556\n",
      "2m 13s (- 6m 40s) (5000 25%) 0.1520\n",
      "2m 39s (- 6m 12s) (6000 30%) 0.1463\n",
      "3m 5s (- 5m 45s) (7000 35%) 0.1427\n",
      "3m 32s (- 5m 19s) (8000 40%) 0.1370\n",
      "3m 58s (- 4m 51s) (9000 45%) 0.1397\n",
      "4m 24s (- 4m 24s) (10000 50%) 0.1384\n",
      "4m 52s (- 3m 59s) (11000 55%) 0.1347\n",
      "5m 18s (- 3m 32s) (12000 60%) 0.1312\n",
      "5m 44s (- 3m 5s) (13000 65%) 0.1307\n",
      "6m 12s (- 2m 39s) (14000 70%) 0.1255\n",
      "6m 38s (- 2m 12s) (15000 75%) 0.1272\n",
      "7m 5s (- 1m 46s) (16000 80%) 0.1208\n",
      "7m 31s (- 1m 19s) (17000 85%) 0.1222\n",
      "7m 58s (- 0m 53s) (18000 90%) 0.1210\n",
      "8m 25s (- 0m 26s) (19000 95%) 0.1173\n",
      "8m 51s (- 0m 0s) (20000 100%) 0.1186\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "encoder1 = EncoderTran(input_lang.n_words).to(device)\n",
    "decoder1 = DecoderTran(output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 20000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 19s (- 2m 54s) (1000 10%) 0.0904\n",
      "0m 41s (- 2m 47s) (2000 20%) 0.0887\n",
      "1m 3s (- 2m 27s) (3000 30%) 0.0929\n",
      "1m 24s (- 2m 7s) (4000 40%) 0.0884\n",
      "1m 45s (- 1m 45s) (5000 50%) 0.0878\n",
      "2m 6s (- 1m 24s) (6000 60%) 0.0839\n",
      "2m 28s (- 1m 3s) (7000 70%) 0.0830\n",
      "2m 49s (- 0m 42s) (8000 80%) 0.0795\n",
      "3m 11s (- 0m 21s) (9000 90%) 0.0766\n",
      "3m 33s (- 0m 0s) (10000 100%) 0.0790\n"
     ]
    }
   ],
   "source": [
    "trainIters(encoder1, decoder1, 10000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length = MAX_LEN):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        \n",
    "        encoder_outputs = encoder(input_tensor)\n",
    "    \n",
    "        decoder_input = torch.tensor([0], device = device)\n",
    "        \n",
    "        decoded_words = []\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output = decoder(decoder_input, encoder_outputs)\n",
    "            topv, topi = decoder_output[di].data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            \n",
    "            decoder_input = torch.cat((decoder_input, torch.tensor([topi.item()], device = device)))\n",
    "            \n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=1):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS je suis meilleur que lui . EOS NNNN NNNN NNNN NNNN\n",
      "= SOS i m better than him . EOS NNNN NNNN NNNN NNNN\n",
      "< i m sorry i m you . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
